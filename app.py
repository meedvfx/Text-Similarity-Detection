import streamlit as st
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer, util

@st.cache_resource 
def load_sbert_model():
    model = SentenceTransformer('all-MiniLM-L6-v2')
    return model
sbert_model = load_sbert_model()

def preprocess_text(text):
    # 1. Minuscules
    text_lower = text.lower()

    # 2. Suppression de tout ce qui n'est pas une lettre ou un espace
    # C'est ici que 're' est utilis√©
    text_cleaned = re.sub(r'[^a-z\s]', '', text_lower)

    # 3. Suppression des espaces multiples
    text_cleaned = re.sub(r'\s+', ' ', text_cleaned).strip()

    return text_cleaned


st.set_page_config(page_title="D√©tecteur de Similarit√©", layout="wide")
st.title("üîé D√©tecteur de Similarit√© de Texte")
st.write("Comparaison de mod√®les pour la d√©tection de similarit√©.")

st.divider()

# --- 1. CHOIX DU MOD√àLE ---
st.header("1. Choisissez votre mod√®le")
model_choice = st.radio(
    "S√©lectionnez la m√©thode d'analyse :",
    ('TF-IDF', 'Sentence-BERT (S-BERT)', 'LSTM'),
    horizontal=True,
    key="model_select",
    help="Choisissez l'algorithme √† utiliser pour la comparaison."
)

# --- 2. OPTIONS CONDITIONNELLES (POUR TF-IDF) ---
# Cette section n'appara√Ætra que si 'TF-IDF' est s√©lectionn√©
ngram_tuple = (1, 1)  # Valeur par d√©faut
if model_choice == 'TF-IDF':
    st.subheader("Options TF-IDF")
    ngram_max = st.selectbox(
        "Taille maximale des N-grams :",
        (1, 2, 3, 4),
        index=0,
        format_func=lambda x: f"{x} (jusqu'√† {x}-grams)" if x > 1 else f"{x} (mots seuls)",
    )
    # TfidfVectorizer attend un tuple (min_n, max_n)
    ngram_tuple = (1, ngram_max)

st.divider()

# --- 3. ENTR√âE DES TEXTES ---
st.header("2. Entrez vos textes")
col1, col2 = st.columns(2)

with col1:
    st.header("Texte 1")
    text1 = st.text_area("Collez votre premier texte ici :", height=300, key="txt1")

with col2:
    st.header("Texte 2")
    text2 = st.text_area("Collez votre deuxi√®me texte ici :", height=300, key="txt2")

st.divider()

# --- 4. BOUTON ET LOGIQUE DE CALCUL ---
if st.button("Calculer la Similarit√©", type="primary"):

    # V√©rifier si les textes sont vides
    if not (text1.strip() and text2.strip()):
        st.warning("Veuillez entrer du texte dans les deux bo√Ætes.")

    else:
        # --- LOGIQUE DE ROUTAGE (selon le mod√®le choisi) ---

        if model_choice == 'TF-IDF':
            st.subheader(f"R√©sultats (Mod√®le : TF-IDF avec N-grams={ngram_tuple})")
            try:
                # 1. Pr√©traitement
                st.write("Pr√©traitement en cours...")
                proc_text1 = preprocess_text(text1)
                proc_text2 = preprocess_text(text2)
                documents = [proc_text1, proc_text2]

                # 2. Vectorisation (AVEC N-GRAMS)
                st.write(f"Vectorisation (TF-IDF) avec n-grams de {ngram_tuple}...")

                # C'est ici que l'option n-gram est pass√©e au mod√®le
                vectorizer = TfidfVectorizer(ngram_range=ngram_tuple)
                tfidf_matrix = vectorizer.fit_transform(documents)

                # 3. Mod√©lisation (Calcul de la similarit√© cosinus)
                st.write("Calcul de la similarit√© cosinus...")
                cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])
                similarity_score = cosine_sim[0][0]

                # Affichage des r√©sultats
                st.divider()
                score_percent = similarity_score * 100
                st.metric(
                    label="Score de Similarit√© (TF-IDF)",
                    value=f"{score_percent:.2f} %"
                )
                st.progress(similarity_score)

                if similarity_score > 0.8:
                    st.error("üö® **Alerte :** Similarit√© tr√®s √©lev√©e. Risque de plagiat.")
                elif similarity_score > 0.5:
                    st.warning("‚ö†Ô∏è **Avertissement :** Similarit√© notable.")
                else:
                    st.success("‚úÖ **OK :** Les textes semblent diff√©rents.")

            except ValueError:
                st.warning("Les textes sont vides apr√®s nettoyage. Impossible de calculer la similarit√©.")

        # --- Blocs pour les futurs mod√®les ---
        elif model_choice == 'Sentence-BERT (S-BERT)':
            st.subheader("R√©sultats (Mod√®le : Sentence-BERT)")

            # S-BERT pr√©f√®re le texte brut, pas de pr√©-traitement !
            documents = [text1, text2]

            # 1. Cr√©er les embeddings (vecteurs s√©mantiques)
            st.write("Calcul des embeddings s√©mantiques...")
            embeddings = sbert_model.encode(documents)

            # 2. Calculer la similarit√© cosinus
            st.write("Calcul de la similarit√© cosinus...")
            # On compare le vecteur 0 et le vecteur 1
            cosine_sim = util.pytorch_cos_sim(embeddings[0], embeddings[1])

            # Extraire le score (c'est un tenseur PyTorch)
            similarity_score = cosine_sim[0][0].item()

            # 3. Afficher les r√©sultats
            st.divider()
            score_percent = similarity_score * 100
            st.metric(
                label="Score de Similarit√© (S-BERT)",
                value=f"{score_percent:.2f} %"
            )
            st.progress(similarity_score)

            if similarity_score > 0.8:
                st.error("üö® **Alerte :** Similarit√© s√©mantique tr√®s √©lev√©e.")
            elif similarity_score > 0.5:
                st.warning("‚ö†Ô∏è **Avertissement :** Similarit√© s√©mantique notable.")
            else:
                st.success("‚úÖ **OK :** Les textes semblent s√©mantiquement diff√©rents.")

            # --- BLOC LSTM (TOUJOURS EN ATTENTE) ---
        elif model_choice == 'LSTM':
            st.subheader("R√©sultats (Mod√®le : LSTM)")
            st.info("üöß Ce mod√®le n'est pas encore d√©velopp√©.")
            st.write("L'impl√©mentation du mod√®le LSTM siamois viendra ici.")
